Introducing RDDs
According to the first white paper released for RDDs, an RDD is a distributed memory abstraction that lets programmers perform in-memory computations on large clusters, in a fault-tolerant manner. The acronym 'RDD' can be expanded as Resilient Distributed Dataset. Some important features of an RDD are as follows:

The term 'RDD' is expanded as Resilient Distributed Dataset, where 'Resilient' refers to fault-tolerant, 'Distributed' refers to data that resides across multiple interconnected nodes, and 'Dataset' is a collection of partitioned data.

RDDs are Spark Core’s abstraction for working with data. In other words, an RDD is a core object that is often used to deal with data in Spark.

An RDD is a fundamental data structure of Spark that is immutable and read-only.

RDDs can include any Python, Java, or Scala objects, or even user-defined classes.

Each dataset is divided into logical partitions that may be computed on different nodes of a cluster. Then, under the hood, Spark distributes the data contained in the RDD internally, among the clusters, and parallelises the operation that you perform on it.


RDDs are broadly classified into two categories: 
==================================================
Basic RDDs:  All the data items in the RDD is a single value.
Paired RDDs:  All the data items in the RDD is a key-value pair.

A basic RDD can be created in two ways in Java. One of the ways of creating an RDD is by converting a Java list to RDD using the parallelize() method defined in SparkContext class.

 

List<Integer> inputIntegers = Arrays.asList(10, 20, 30, 40, 50);
JavaRDD<Integer> integerRdd = sc.parallelize(inputIntegers);

 

This approach is handy but not very practical in real life scenario because the entire data in the "inputIntegers" list should fit in the driver’s memory before it is distributed across the cluster. The other way of creating a basic RDD is by reading data from a file stored in an external filesystem such as HDFS. The textFile() method defined in SparkContext class is used to read a file.

 

JavaRDD<String> ratings = sc.textFile("in/u.data");
 

In the above code "in/u.data" is the relative address of the file "u.data". 

 

Paired RDDs are created by transforming a basic RDD to pairedRDD using various transformation operations such as mapToPair and flatMapToPair. You will learn these operations in detail in the upcoming sessions.

